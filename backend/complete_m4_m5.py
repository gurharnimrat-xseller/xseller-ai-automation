"""
Complete M4 & M5 with detailed tasks + add missing metadata
"""
import os
from datetime import datetime, timedelta
from notion_client import Client
from dotenv import load_dotenv

load_dotenv()

client = Client(auth=os.getenv("NOTION_API_KEY"))
db_id = os.getenv("NOTION_DATABASE_ID")

def create_detailed_task(title, summary, milestone, status, owner, priority, eod_date, effort_hours=None, tags=None, acceptance_criteria=None):
    """Create a detailed task with all metadata"""
    try:
        properties = {
            "Item": {
                "title": [{"text": {"content": title}}]
            },
            "Entry Type": {
                "select": {"name": "Task"}
            },
            "Owner": {
                "rich_text": [{"text": {"content": owner}}]
            },
            "Status": {
                "status": {"name": status}
            },
            "Milestone": {
                "select": {"name": milestone}
            },
            "Priority": {
                "select": {"name": priority}
            },
            "Summary / Notes": {
                "rich_text": [{"text": {"content": summary[:1900]}}]  # Leave buffer for safety
            },
            "EOD Date": {
                "date": {"start": eod_date.isoformat()}
            }
        }

        # Add effort hours if provided
        if effort_hours:
            properties["Effort (hours)"] = {"number": effort_hours}

        # Add tags if provided
        if tags:
            properties["Tags"] = {
                "multi_select": [{"name": tag} for tag in tags]
            }

        # Add acceptance criteria to summary
        if acceptance_criteria:
            properties["Acceptance Criteria"] = {
                "rich_text": [{"text": {"content": acceptance_criteria[:2000]}}]
            }

        response = client.pages.create(
            parent={"database_id": db_id},
            properties=properties
        )

        print(f"‚úÖ {title}")
        return response

    except Exception as e:
        print(f"‚ùå Failed: {title} - {str(e)}")
        return None

# Calculate dates
today = datetime.now()
m4_start = today + timedelta(days=22)  # Week 4
m5_start = today + timedelta(days=29)  # Week 5

print("="*80)
print("üöÄ COMPLETING M4 & M5 WITH FULL DETAILS")
print("="*80)

# ==========================================
# MILESTONE 4: REVIEW INTERFACE (Week 4)
# ==========================================
print("\nüìã MILESTONE 4: Review Interface (Week 4)")

create_detailed_task(
    title="M4A: Queue Enhancement UI - Video Preview System",
    summary="""Build comprehensive video review interface in Next.js frontend

üéØ Goal: Create intuitive UI for reviewing generated videos before approval

üìã Tasks:
1. Video Preview Player
   ‚Ä¢ Integrate Video.js or React Player
   ‚Ä¢ Support 1080x1920 vertical format
   ‚Ä¢ Controls: play, pause, seek, volume
   ‚Ä¢ Fullscreen mode for mobile testing
   ‚Ä¢ Playback speed control (0.5x - 2x)

2. Script Display Panel
   ‚Ä¢ Show script text alongside video
   ‚Ä¢ Highlight current segment during playback
   ‚Ä¢ Inline editing capability (contentEditable)
   ‚Ä¢ Word count and timing display
   ‚Ä¢ Save changes with version history

3. B-Roll Thumbnail Grid
   ‚Ä¢ Display all B-roll clips used
   ‚Ä¢ Show timestamp ranges for each clip
   ‚Ä¢ Click to preview individual clip
   ‚Ä¢ Swap clip button (search alternative)
   ‚Ä¢ Add/remove clips functionality

4. Voice Sample Playback
   ‚Ä¢ Separate audio player for voice only
   ‚Ä¢ Compare with original script text
   ‚Ä¢ Show audio waveform visualization
   ‚Ä¢ Identify pauses and emphasis points
   ‚Ä¢ Re-generate voice button

5. Approve/Reject Workflow
   ‚Ä¢ Large approve button (green)
   ‚Ä¢ Reject with reason (opens feedback modal)
   ‚Ä¢ Request changes (specific issues)
   ‚Ä¢ Save draft for later review
   ‚Ä¢ Keyboard shortcuts (A=approve, R=reject)

üîß Technical Implementation:
‚Ä¢ Frontend: Next.js + TypeScript + Tailwind CSS
‚Ä¢ Video Player: Video.js (customized for vertical)
‚Ä¢ State Management: React Context or Zustand
‚Ä¢ API: FastAPI endpoints for CRUD operations
‚Ä¢ Real-time updates: WebSocket for queue changes

üìÅ File Structure:
frontend/components/VideoPreview.tsx
frontend/components/ScriptEditor.tsx
frontend/components/BRollGrid.tsx
frontend/components/ApprovalButtons.tsx
frontend/hooks/useVideoQueue.ts
frontend/api/videoQueue.ts

‚úÖ Acceptance Criteria:
‚Ä¢ Video plays smoothly in browser (no lag)
‚Ä¢ Script editing saves immediately (debounced)
‚Ä¢ B-roll grid shows all clips with thumbnails
‚Ä¢ Approve/reject updates database instantly
‚Ä¢ Keyboard shortcuts work
‚Ä¢ Mobile responsive (works on phone)
‚Ä¢ Can review 10 videos in < 5 minutes
‚Ä¢ Zero bugs in user testing

üìä Estimated Effort: 16 hours (2 days)

üß™ Testing:
‚Ä¢ Load test with 50 videos in queue
‚Ä¢ Test on Chrome, Safari, Firefox
‚Ä¢ Test on iPhone and Android
‚Ä¢ Verify video playback quality
‚Ä¢ Test keyboard shortcuts
‚Ä¢ Check accessibility (WCAG AA)""",
    milestone="M4: Review",
    status="Todo",
    owner="Claude",
    priority="High",
    eod_date=m4_start + timedelta(days=1),
    effort_hours=16,
    tags=["frontend", "ui", "react", "video"],
    acceptance_criteria="Video plays smoothly, script edits save, B-roll grid works, approve/reject instant, keyboard shortcuts, mobile responsive"
)

create_detailed_task(
    title="M4B: Structured Feedback Modal - Issue Taxonomy System",
    summary="""Build feedback collection system for targeted improvements

üéØ Goal: Capture specific, actionable feedback for regeneration

üìã Tasks:
1. Feedback Modal Design
   ‚Ä¢ Opens when "Request Changes" clicked
   ‚Ä¢ Categorized feedback sections
   ‚Ä¢ Visual issue markers on video timeline
   ‚Ä¢ Before/after comparison preview
   ‚Ä¢ Submit with confidence (regenerate now vs later)

2. Feedback Taxonomy
   Categories:

   A) Script Issues:
      ‚ñ° Hook not engaging enough
      ‚ñ° Context too long/short
      ‚ñ° Main point unclear
      ‚ñ° CTA not compelling
      ‚ñ° Tone mismatch (too formal/casual)
      ‚ñ° Factual errors
      ‚ñ° Grammar/spelling issues

   B) Voice Issues:
      ‚ñ° Speed too fast/slow
      ‚ñ° Energy too high/low
      ‚ñ° Pronunciation errors
      ‚ñ° Awkward pauses
      ‚ñ° Wrong emphasis
      ‚ñ° Voice mismatch (want different voice)

   C) B-Roll Issues:
      ‚ñ° Clip not relevant to content
      ‚ñ° Low quality/blurry
      ‚ñ° Wrong orientation (not vertical)
      ‚ñ° Scene change too fast/slow
      ‚ñ° Needs different keyword search
      ‚ñ° Missing B-roll for segment

   D) Audio Mix Issues:
      ‚ñ° Voice too quiet/loud
      ‚ñ° Music too prominent
      ‚ñ° Background noise
      ‚ñ° Audio sync off
      ‚ñ° Transitions jarring

   E) Text Overlay Issues:
      ‚ñ° Text not readable
      ‚ñ° Wrong timing
      ‚ñ° Emphasis on wrong words
      ‚ñ° Style doesn't match
      ‚ñ° Too many/few overlays

3. Rating System
   ‚Ä¢ Overall quality: 1-5 stars
   ‚Ä¢ Individual components: 1-5 stars each
     - Script: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
     - Voice: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
     - B-roll: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
     - Audio Mix: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
     - Text Overlays: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
   ‚Ä¢ Auto-calculate weighted average

4. Free-Form Notes
   ‚Ä¢ Text area for additional comments
   ‚Ä¢ Attach screenshots (drag-drop)
   ‚Ä¢ Tag team members (@mention)
   ‚Ä¢ Link to reference videos
   ‚Ä¢ Save as template for recurring issues

5. Submission Actions
   ‚Ä¢ Regenerate Now (high priority queue)
   ‚Ä¢ Save Feedback (review later)
   ‚Ä¢ Minor Edits Only (don't regenerate)
   ‚Ä¢ Approve with Notes (track for learning)

üîß Technical Implementation:
‚Ä¢ Modal: Headless UI + Tailwind
‚Ä¢ Form: React Hook Form + Zod validation
‚Ä¢ Storage: PostgreSQL feedback table
‚Ä¢ Analytics: Track most common issues
‚Ä¢ ML: Cluster feedback for pattern detection

üìÅ File Structure:
frontend/components/FeedbackModal.tsx
frontend/components/FeedbackTaxonomy.tsx
frontend/components/RatingStars.tsx
frontend/types/feedback.ts
backend/app/models/feedback.py
backend/app/routes/feedback.py

‚úÖ Acceptance Criteria:
‚Ä¢ All feedback categories present
‚Ä¢ Can select multiple issues per category
‚Ä¢ Rating system intuitive (star clicks)
‚Ä¢ Free-form notes support markdown
‚Ä¢ Submission stores in database
‚Ä¢ Feedback visible in video history
‚Ä¢ Can filter videos by feedback type
‚Ä¢ Analytics show top 5 issues

üìä Estimated Effort: 8 hours (1 day)

üß™ Testing:
‚Ä¢ Submit feedback for 10 test videos
‚Ä¢ Verify all categories work
‚Ä¢ Check database storage
‚Ä¢ Test rating calculations
‚Ä¢ Validate required fields
‚Ä¢ Test with missing data""",
    milestone="M4: Review",
    status="Todo",
    owner="Claude",
    priority="High",
    eod_date=m4_start + timedelta(days=2),
    effort_hours=8,
    tags=["frontend", "forms", "feedback", "ui"],
    acceptance_criteria="All categories work, ratings intuitive, notes save, database stores feedback, can filter by issue type"
)

create_detailed_task(
    title="M4C: Regeneration Backend - Feedback-Driven Improvements",
    summary="""Build intelligent regeneration system that applies feedback

üéØ Goal: Automatically improve videos based on structured feedback

üìã Tasks:
1. Feedback Parser
   ‚Ä¢ Parse structured feedback JSON
   ‚Ä¢ Extract actionable changes
   ‚Ä¢ Prioritize changes by impact
   ‚Ä¢ Group related issues
   ‚Ä¢ Generate regeneration plan

2. Script Adjustment Engine
   If feedback includes script issues:

   A) Hook Issues:
      ‚Ä¢ Regenerate hook with "more engaging" prompt
      ‚Ä¢ Try 3 variations, score by engagement
      ‚Ä¢ A/B test against original

   B) Tone Issues:
      ‚Ä¢ Adjust prompt: "more casual" or "more professional"
      ‚Ä¢ Maintain key facts
      ‚Ä¢ Re-check word count

   C) Length Issues:
      ‚Ä¢ "Expand context" or "trim to essentials"
      ‚Ä¢ Preserve hook and CTA
      ‚Ä¢ Verify 30-60 sec target

   D) Factual Errors:
      ‚Ä¢ Flag for human review
      ‚Ä¢ Don't auto-regenerate (safety)
      ‚Ä¢ Provide correction interface

3. Voice Re-generation
   If feedback includes voice issues:

   A) Speed Adjustment:
      ‚Ä¢ Too fast: reduce speed to 0.9x
      ‚Ä¢ Too slow: increase to 1.1x
      ‚Ä¢ Re-export audio

   B) Energy Adjustment:
      ‚Ä¢ Too high: reduce stability to 0.6
      ‚Ä¢ Too low: increase stability to 0.4
      ‚Ä¢ Test with sample

   C) Voice Change:
      ‚Ä¢ Switch to alternative voice
      ‚Ä¢ Re-generate entire audio
      ‚Ä¢ Keep timing sync

   D) Pronunciation Fixes:
      ‚Ä¢ Use SSML tags for pronunciation
      ‚Ä¢ Add phonetic spelling
      ‚Ä¢ Test problematic words

4. B-Roll Replacement
   If feedback includes B-roll issues:

   A) Relevance Issues:
      ‚Ä¢ Use feedback notes as new search term
      ‚Ä¢ Re-search Artlist with improved keywords
      ‚Ä¢ Preview top 3 alternatives
      ‚Ä¢ Auto-select highest quality

   B) Quality Issues:
      ‚Ä¢ Filter for 4K minimum
      ‚Ä¢ Check resolution before download
      ‚Ä¢ Reject < 1080p vertical

   C) Timing Issues:
      ‚Ä¢ Adjust sync engine parameters
      ‚Ä¢ Longer/shorter clip duration
      ‚Ä¢ Adjust fade transition timing

5. Reassembly Pipeline
   ‚Ä¢ Keep unchanged components
   ‚Ä¢ Replace only flagged segments
   ‚Ä¢ Re-run FFmpeg assembly
   ‚Ä¢ Re-run quality checks
   ‚Ä¢ Compare before/after
   ‚Ä¢ Log all changes for learning

6. Version Control
   ‚Ä¢ Store original video (v1)
   ‚Ä¢ Store regenerated video (v2, v3, ...)
   ‚Ä¢ Track what changed between versions
   ‚Ä¢ Allow rollback to previous version
   ‚Ä¢ Compare metrics (v2 vs v1 performance)

7. Learning Loop
   ‚Ä¢ Track: Feedback ‚Üí Changes ‚Üí Approval
   ‚Ä¢ Identify patterns:
     - "Hook issue" + "regenerate" ‚Üí approved 80%
     - "B-roll issue" ‚Üí approved 95%
   ‚Ä¢ Update default prompts based on patterns
   ‚Ä¢ Build knowledge base of fixes
   ‚Ä¢ Auto-suggest fixes for common issues

üîß Technical Implementation:
‚Ä¢ Backend: Python + FastAPI
‚Ä¢ Queue: Celery for async regeneration
‚Ä¢ Storage: S3 for video versions
‚Ä¢ Diff: Video comparison library
‚Ä¢ ML: Scikit-learn for pattern detection

üìÅ File Structure:
backend/app/feedback_parser.py
backend/app/script_adjuster.py
backend/app/voice_regenerator.py
backend/app/broll_replacer.py
backend/app/reassembly.py
backend/app/version_control.py
backend/app/learning_loop.py

‚úÖ Acceptance Criteria:
‚Ä¢ Feedback JSON parsed correctly
‚Ä¢ Script adjustments applied accurately
‚Ä¢ Voice regeneration respects parameters
‚Ä¢ B-roll replaced with better clips
‚Ä¢ Reassembly produces valid video
‚Ä¢ Version history tracked
‚Ä¢ Can compare v1 vs v2 side-by-side
‚Ä¢ Learning loop improves over time (test with 50 videos)
‚Ä¢ 80%+ of regenerations approved

üìä Estimated Effort: 16 hours (2 days)

üß™ Testing:
‚Ä¢ Test each feedback category separately
‚Ä¢ Submit 10 videos with different issues
‚Ä¢ Verify each issue type regenerates correctly
‚Ä¢ Check version history accuracy
‚Ä¢ Test rollback functionality
‚Ä¢ Measure improvement rate over 50 videos""",
    milestone="M4: Review",
    status="Todo",
    owner="Codex",
    priority="High",
    eod_date=m4_start + timedelta(days=4),
    effort_hours=16,
    tags=["backend", "ml", "feedback", "regeneration"],
    acceptance_criteria="Feedback parsed, script adjusts, voice regenerates, B-roll replaces, reassembly works, versions tracked, 80% approval"
)

# ==========================================
# MILESTONE 5: PUBLISHING & AUTOMATION (Week 5)
# ==========================================
print("\nüìã MILESTONE 5: Publishing & Automation (Week 5)")

create_detailed_task(
    title="M5A: Multi-Platform Publishing - Publer Integration",
    summary="""Integrate Publer API for automated social media posting

üéØ Goal: Post approved videos to all platforms automatically

üìã Tasks:
1. Publer API Setup
   ‚Ä¢ Create Publer account (free tier)
   ‚Ä¢ Connect social accounts:
     - YouTube (Shorts)
     - TikTok
     - Instagram (Reels)
     - Facebook (Reels)
     - LinkedIn (Video)
   ‚Ä¢ Generate API key
   ‚Ä¢ Test authentication

2. Platform-Specific Formatting

   A) YouTube Shorts:
      ‚Ä¢ Format: 9:16, max 60s
      ‚Ä¢ Title: SEO optimized (50 chars)
      ‚Ä¢ Description: Full with hashtags
      ‚Ä¢ Hashtags: #Shorts #AI #Tech (max 15)
      ‚Ä¢ Thumbnail: Custom 1080x1920
      ‚Ä¢ Category: Science & Technology
      ‚Ä¢ Visibility: Public

   B) TikTok:
      ‚Ä¢ Format: 9:16, max 60s
      ‚Ä¢ Caption: Engaging (150 chars)
      ‚Ä¢ Hashtags: Trending (5-8)
      ‚Ä¢ Cover: Auto-select best frame
      ‚Ä¢ Privacy: Public
      ‚Ä¢ Comments: Enabled
      ‚Ä¢ Duet/Stitch: Enabled

   C) Instagram Reels:
      ‚Ä¢ Format: 9:16, max 90s
      ‚Ä¢ Caption: Branded (2200 chars max)
      ‚Ä¢ Hashtags: Mix of popular + niche (30 max)
      ‚Ä¢ Cover: Custom frame
      ‚Ä¢ Location: Add if relevant
      ‚Ä¢ Tag: Brands mentioned

   D) Facebook Reels:
      ‚Ä¢ Format: 9:16, max 60s
      ‚Ä¢ Caption: Same as Instagram
      ‚Ä¢ Hashtags: 5-10
      ‚Ä¢ Thumbnail: Auto
      ‚Ä¢ Audience: Public

   E) LinkedIn:
      ‚Ä¢ Format: 16:9 (re-export!)
      ‚Ä¢ Duration: Up to 10 min (use 60s)
      ‚Ä¢ Caption: Professional tone
      ‚Ä¢ Hashtags: Industry specific
      ‚Ä¢ Visibility: Public

3. Video Conversion Service
   ‚Ä¢ Most platforms: Use existing 1080x1920
   ‚Ä¢ LinkedIn: Convert to 1920x1080 (16:9)
   ‚Ä¢ FFmpeg command:
     ```
     ffmpeg -i vertical.mp4 \\
       -vf "scale=1920:1080:force_original_aspect_ratio=decrease,pad=1920:1080:(ow-iw)/2:(oh-ih)/2" \\
       -c:v libx264 -c:a copy horizontal.mp4
     ```
   ‚Ä¢ Cache conversions (don't regenerate)

4. Caption Generation
   ‚Ä¢ Extract key points from script
   ‚Ä¢ Platform-specific tone:
     - YouTube: Educational + SEO keywords
     - TikTok: Casual + trending phrases
     - Instagram: Branded + emojis
     - LinkedIn: Professional + thought leadership
   ‚Ä¢ Auto-generate hashtags based on content
   ‚Ä¢ Emoji insertion (platform appropriate)

5. Hashtag Strategy
   ‚Ä¢ Scrape trending hashtags per platform
   ‚Ä¢ Mix strategy:
     - 30% high-volume (100k+ posts)
     - 50% medium-volume (10k-100k posts)
     - 20% niche (1k-10k posts)
   ‚Ä¢ Store hashtag performance data
   ‚Ä¢ Update strategy weekly

6. Publishing Queue
   ‚Ä¢ Batch upload approved videos
   ‚Ä¢ Schedule posts (best times per platform)
   ‚Ä¢ Stagger: Don't post all at once
   ‚Ä¢ Retry failed uploads (3 attempts)
   ‚Ä¢ Log all publishing activity
   ‚Ä¢ Send notification on success/failure

7. Error Handling
   ‚Ä¢ API rate limits: Respect and queue
   ‚Ä¢ Upload failures: Retry with exponential backoff
   ‚Ä¢ Invalid format: Re-convert and retry
   ‚Ä¢ Caption too long: Auto-truncate with "..."
   ‚Ä¢ Hashtag limit: Trim to platform max
   ‚Ä¢ Network errors: Queue for later

üîß Technical Implementation:
‚Ä¢ API: Publer REST API (Python SDK)
‚Ä¢ Queue: Redis for publishing queue
‚Ä¢ Scheduler: APScheduler or Celery Beat
‚Ä¢ Storage: S3 for platform-specific videos
‚Ä¢ Monitoring: Track success/failure rates

üìÅ File Structure:
backend/app/publer_service.py
backend/app/platform_formatter.py
backend/app/caption_generator.py
backend/app/hashtag_strategy.py
backend/app/publishing_queue.py
backend/app/video_converter.py

‚úÖ Acceptance Criteria:
‚Ä¢ Can post to all 5 platforms
‚Ä¢ Platform-specific formatting applied
‚Ä¢ Captions auto-generated correctly
‚Ä¢ Hashtags relevant and trending
‚Ä¢ LinkedIn video converted to 16:9
‚Ä¢ Publishing queue processes in order
‚Ä¢ Retry logic handles failures
‚Ä¢ Success rate > 95%
‚Ä¢ Can publish 10 videos in 10 minutes

üìä Estimated Effort: 16 hours (2 days)

üß™ Testing:
‚Ä¢ Post test video to each platform
‚Ä¢ Verify format on mobile devices
‚Ä¢ Check captions render correctly
‚Ä¢ Test hashtag clickability
‚Ä¢ Simulate API failures
‚Ä¢ Test rate limit handling
‚Ä¢ Verify retry logic works
‚Ä¢ Monitor for 48 hours""",
    milestone="M5: Publishing",
    status="Todo",
    owner="Codex",
    priority="High",
    eod_date=m5_start + timedelta(days=1),
    effort_hours=16,
    tags=["backend", "api", "social-media", "publishing"],
    acceptance_criteria="Posts to 5 platforms, formatting correct, captions generate, hashtags relevant, 95% success rate"
)

create_detailed_task(
    title="M5B: Analytics Dashboard - Performance Tracking System",
    summary="""Build comprehensive analytics dashboard for video performance

üéØ Goal: Track video performance across platforms and identify patterns

üìã Tasks:
1. Publer Analytics Integration
   ‚Ä¢ Fetch metrics via Publer API:
     - Views
     - Likes
     - Comments
     - Shares
     - Saves (Instagram/TikTok)
     - Engagement rate
     - Reach
     - Impressions
   ‚Ä¢ Schedule: Fetch every 6 hours
   ‚Ä¢ Store in PostgreSQL time-series table
   ‚Ä¢ Calculate 24hr, 7day, 30day trends

2. Dashboard UI (Frontend)

   A) Overview Section:
      ‚Ä¢ Total videos published (all-time)
      ‚Ä¢ Total views (all platforms combined)
      ‚Ä¢ Average engagement rate
      ‚Ä¢ Best performing video (this week)
      ‚Ä¢ Publishing velocity (videos/day)
      ‚Ä¢ Platform breakdown (pie chart)

   B) Performance Charts:
      ‚Ä¢ Line chart: Views over time (7/30/90 days)
      ‚Ä¢ Bar chart: Engagement by platform
      ‚Ä¢ Heatmap: Best posting times
      ‚Ä¢ Funnel: Approval ‚Üí Published ‚Üí Views

   C) Video Leaderboard:
      ‚Ä¢ Top 10 videos by views
      ‚Ä¢ Top 10 by engagement rate
      ‚Ä¢ Worst 5 performers (learn from failures)
      ‚Ä¢ Sortable table with filters

   D) Platform Comparison:
      ‚Ä¢ Side-by-side metrics per platform
      ‚Ä¢ Which platform drives most views?
      ‚Ä¢ Which has highest engagement?
      ‚Ä¢ ROI per platform (effort vs results)

   E) Retention Analysis:
      ‚Ä¢ YouTube: Retention curve (% watched)
      ‚Ä¢ Average watch time per video
      ‚Ä¢ Drop-off points (where users leave)
      ‚Ä¢ Identify ideal video length

   F) Audience Insights:
      ‚Ä¢ Demographics (age, gender, location)
      ‚Ä¢ Peak activity hours
      ‚Ä¢ Device breakdown (mobile vs desktop)
      ‚Ä¢ Traffic sources (browse, search, suggested)

3. Real-Time Monitoring
   ‚Ä¢ WebSocket connection for live updates
   ‚Ä¢ Notifications for milestone hits:
     - First 1K views
     - 10K views
     - 100K views
     - Viral threshold (1M views)
   ‚Ä¢ Alert on unusual patterns (sudden spike/drop)

4. Automated Reporting
   ‚Ä¢ Daily summary email (9 AM):
     - Yesterday's total views
     - Top performing video
     - Publishing schedule for today
   ‚Ä¢ Weekly digest (Monday morning):
     - Last 7 days performance
     - Week-over-week growth
     - Top 5 videos
     - Recommendations for next week
   ‚Ä¢ Monthly report (1st of month):
     - Full month metrics
     - Goal progress (views, engagement)
     - Cost analysis (API usage)
     - Strategic recommendations

5. Competitive Benchmarking
   ‚Ä¢ Track competitor accounts (public data)
   ‚Ä¢ Compare: Views, engagement, posting frequency
   ‚Ä¢ Identify: What works for them?
   ‚Ä¢ Alerts: When competitor goes viral (learn from it)

6. Export & Sharing
   ‚Ä¢ Export data: CSV, JSON, PDF
   ‚Ä¢ Share dashboard: Public link (read-only)
   ‚Ä¢ Embed charts: Iframe for Notion/Confluence
   ‚Ä¢ API access: GraphQL endpoint for custom queries

üîß Technical Implementation:
‚Ä¢ Frontend: Next.js + Recharts/Chart.js
‚Ä¢ Backend: FastAPI + PostgreSQL
‚Ä¢ Time-series: TimescaleDB extension
‚Ä¢ Caching: Redis for dashboard data
‚Ä¢ Real-time: WebSocket (Socket.io)
‚Ä¢ Reporting: SendGrid for email

üìÅ File Structure:
frontend/app/analytics/page.tsx
frontend/components/AnalyticsOverview.tsx
frontend/components/PerformanceCharts.tsx
frontend/components/VideoLeaderboard.tsx
backend/app/analytics_service.py
backend/app/reporting.py
backend/app/metrics_aggregator.py

‚úÖ Acceptance Criteria:
‚Ä¢ Dashboard loads in < 2 seconds
‚Ä¢ All charts render correctly
‚Ä¢ Real-time updates work (test with mock data)
‚Ä¢ Metrics match platform directly (verify accuracy)
‚Ä¢ Daily email arrives on schedule
‚Ä¢ Export functions work (CSV, PDF)
‚Ä¢ Can track 100+ videos without slowdown
‚Ä¢ Mobile responsive design

üìä Estimated Effort: 16 hours (2 days)

üß™ Testing:
‚Ä¢ Load test with 500 videos
‚Ä¢ Verify chart accuracy (manual comparison)
‚Ä¢ Test real-time updates (simulate new views)
‚Ä¢ Check email delivery
‚Ä¢ Test export formats
‚Ä¢ Mobile responsiveness check
‚Ä¢ Accessibility audit (WCAG AA)""",
    milestone="M5: Publishing",
    status="Todo",
    owner="Claude",
    priority="High",
    eod_date=m5_start + timedelta(days=3),
    effort_hours=16,
    tags=["frontend", "analytics", "charts", "dashboard"],
    acceptance_criteria="Dashboard loads fast, charts accurate, real-time works, emails send, exports work, handles 100+ videos"
)

create_detailed_task(
    title="M5C: Learning Loop - Continuous Improvement System",
    summary="""Build ML system that learns from performance data

üéØ Goal: Automatically improve content strategy based on what works

üìã Tasks:
1. Data Collection Pipeline
   ‚Ä¢ Collect all video metadata:
     - Script (topic, keywords, structure)
     - Voice (speed, energy, voice type)
     - B-roll (clip types, timing)
     - Music (track, tempo)
     - Text overlays (style, frequency)
     - Duration (seconds)
     - Posting time (hour, day of week)
     - Platform
   ‚Ä¢ Collect performance metrics:
     - Views (1hr, 24hr, 7day, 30day)
     - Engagement rate
     - Watch time
     - Retention curve
     - Comments sentiment (positive/negative/neutral)
   ‚Ä¢ Store in structured format (JSON + DB)

2. Pattern Detection (ML)

   A) Script Analysis:
      ‚Ä¢ What topics get most views?
      ‚Ä¢ Ideal script length (word count)?
      ‚Ä¢ Hook patterns that work
      ‚Ä¢ CTA phrases with highest CTR
      ‚Ä¢ Keyword density correlation

   B) Voice Analysis:
      ‚Ä¢ Best voice for each topic
      ‚Ä¢ Optimal speaking speed (WPM)
      ‚Ä¢ Energy level vs engagement
      ‚Ä¢ Pause patterns and retention

   C) B-Roll Analysis:
      ‚Ä¢ Which clip types get most retention?
      ‚Ä¢ Optimal scene change frequency
      ‚Ä¢ Clip quality vs engagement
      ‚Ä¢ Best search keywords per topic

   D) Timing Analysis:
      ‚Ä¢ Best posting times per platform
      ‚Ä¢ Day of week performance
      ‚Ä¢ Optimal publishing frequency
      ‚Ä¢ Seasonal trends

   E) Format Analysis:
      ‚Ä¢ Ideal video duration
      ‚Ä¢ Text overlay frequency
      ‚Ä¢ Music tempo preference
      ‚Ä¢ Thumbnail style

3. Recommendation Engine
   Based on analysis, generate recommendations:

   ‚Ä¢ "AI news videos perform 2x better than crypto news"
     ‚Üí Action: Prioritize AI topics in scraper

   ‚Ä¢ "Videos with 'Breaking:' in hook get 50% more views"
     ‚Üí Action: Update script template to use "Breaking:"

   ‚Ä¢ "Voice speed at 160 WPM has best retention"
     ‚Üí Action: Adjust TTS speed parameter

   ‚Ä¢ "Best posting time: Tuesday 9 AM EST"
     ‚Üí Action: Schedule videos for Tuesdays

   ‚Ä¢ "TikTok performs 3x better than Instagram"
     ‚Üí Action: Optimize for TikTok first

4. Automated Adjustments
   ‚Ä¢ Confidence threshold: Only apply if 80%+ confident
   ‚Ä¢ Gradual changes: A/B test before full rollout
   ‚Ä¢ Version control: Track what changed and why
   ‚Ä¢ Rollback: Revert if performance drops

   Example Auto-Adjustments:

   A) Script Template:
      ‚Ä¢ Update hook patterns
      ‚Ä¢ Adjust ideal word count
      ‚Ä¢ Add/remove CTA phrases
      ‚Ä¢ Modify keyword density

   B) Voice Settings:
      ‚Ä¢ Change default speed
      ‚Ä¢ Adjust energy level
      ‚Ä¢ Switch default voice

   C) B-Roll Strategy:
      ‚Ä¢ Update search keywords
      ‚Ä¢ Adjust scene change timing
      ‚Ä¢ Filter clip types

   D) Publishing Schedule:
      ‚Ä¢ Shift posting times
      ‚Ä¢ Change frequency
      ‚Ä¢ Prioritize platforms

5. A/B Testing Framework
   ‚Ä¢ Control group: Use current settings
   ‚Ä¢ Test group: Use recommended changes
   ‚Ä¢ Sample size: 20 videos per group
   ‚Ä¢ Duration: 7 days
   ‚Ä¢ Measure: Views, engagement, retention
   ‚Ä¢ Statistical significance: p < 0.05
   ‚Ä¢ Winner: Apply to all future videos

6. Performance Dashboard
   ‚Ä¢ Show learning progress over time
   ‚Ä¢ Display: Before/after metrics
   ‚Ä¢ Highlight: Successful adjustments
   ‚Ä¢ Flag: Failed experiments
   ‚Ä¢ Track: ROI of learning loop

   Metrics:
   ‚Ä¢ Baseline avg views: 10K
   ‚Ä¢ After 30 days: 15K (+50%)
   ‚Ä¢ After 60 days: 20K (+100%)
   ‚Ä¢ After 90 days: 25K (+150%)

7. Knowledge Base
   ‚Ä¢ Document all learnings
   ‚Ä¢ Create playbook:
     - "How to write viral hooks"
     - "Best B-roll for AI topics"
     - "Optimal posting schedule"
   ‚Ä¢ Share with team
   ‚Ä¢ Export as markdown for Notion

üîß Technical Implementation:
‚Ä¢ ML: Scikit-learn (classification, regression)
‚Ä¢ Statistical analysis: SciPy (hypothesis testing)
‚Ä¢ Visualization: Matplotlib + Seaborn
‚Ä¢ Data: Pandas DataFrames
‚Ä¢ Storage: PostgreSQL + S3 (raw data)
‚Ä¢ Automation: Celery tasks (daily analysis)

üìÅ File Structure:
backend/app/ml/data_collector.py
backend/app/ml/pattern_detector.py
backend/app/ml/recommendation_engine.py
backend/app/ml/ab_testing.py
backend/app/ml/auto_adjuster.py
backend/app/ml/knowledge_base.py

‚úÖ Acceptance Criteria:
‚Ä¢ Collects data for 50+ videos
‚Ä¢ Detects at least 5 patterns (statistically significant)
‚Ä¢ Generates 10+ recommendations
‚Ä¢ A/B tests 3 recommendations
‚Ä¢ At least 1 recommendation improves performance
‚Ä¢ Auto-applies winning changes
‚Ä¢ Knowledge base generated
‚Ä¢ Performance improves 10%+ over 30 days

üìä Estimated Effort: 8 hours (1 day)

üß™ Testing:
‚Ä¢ Run analysis on 50 test videos
‚Ä¢ Verify patterns are real (not spurious)
‚Ä¢ Test recommendation logic
‚Ä¢ Simulate A/B test results
‚Ä¢ Check auto-adjustment safety
‚Ä¢ Verify rollback works
‚Ä¢ Measure improvement over time""",
    milestone="M5: Publishing",
    status="Todo",
    owner="Claude + Codex",
    priority="Medium",
    eod_date=m5_start + timedelta(days=4),
    effort_hours=8,
    tags=["ml", "analytics", "optimization", "backend"],
    acceptance_criteria="Collects data, detects patterns, generates recommendations, A/B tests, auto-applies, performance improves 10%+"
)

# ==========================================
# FINAL INTEGRATION TEST
# ==========================================
print("\nüìã FINAL MILESTONE: Integration & Launch")

create_detailed_task(
    title="M5D: End-to-End Integration Test - Full Automation",
    summary="""Test complete system running autonomously for 1 week

üéØ Goal: Prove system can operate 24/7 with zero manual intervention

üìã Test Scenarios:

1. Daily Automation Test (7 Days)

   Day 1:
   ‚Ä¢ System scrapes news at 6 AM
   ‚Ä¢ Generates 3 scripts by 7 AM
   ‚Ä¢ Creates 3 videos by 9 AM
   ‚Ä¢ All pass quality checks
   ‚Ä¢ Added to review queue
   ‚Ä¢ Human reviews and approves 2, rejects 1
   ‚Ä¢ 2 videos published at optimal times
   ‚Ä¢ Analytics update within 1 hour
   ‚Ä¢ Notion daily update posted

   Day 2-7:
   ‚Ä¢ Repeat same cycle
   ‚Ä¢ Test regeneration (at least 3 videos)
   ‚Ä¢ Test different topics (AI, crypto, tech)
   ‚Ä¢ Test all platforms (rotate)
   ‚Ä¢ Test feedback loop improvements
   ‚Ä¢ Test error recovery (simulate failures)

2. Error Handling Tests

   A) API Failures:
      ‚Ä¢ Gemini API down ‚Üí Use cached templates
      ‚Ä¢ ElevenLabs down ‚Üí Queue for retry
      ‚Ä¢ Artlist down ‚Üí Use Pexels fallback
      ‚Ä¢ Publer down ‚Üí Queue for later

   B) Content Issues:
      ‚Ä¢ No news articles found ‚Üí Alert human
      ‚Ä¢ Script generation fails ‚Üí Retry with simplified prompt
      ‚Ä¢ TTS fails ‚Üí Try alternative voice
      ‚Ä¢ B-roll search returns 0 ‚Üí Use stock fallback

   C) Quality Failures:
      ‚Ä¢ Video corruption ‚Üí Regenerate
      ‚Ä¢ Audio sync off ‚Üí Rebuild timeline
      ‚Ä¢ File size too large ‚Üí Compress
      ‚Ä¢ Platform rejection ‚Üí Reformat and resubmit

3. Performance Tests
   ‚Ä¢ Load: Generate 20 videos simultaneously
   ‚Ä¢ Speed: Full pipeline completes in < 30 min
   ‚Ä¢ Quality: 90%+ videos pass QC on first try
   ‚Ä¢ Approval: 80%+ videos approved by human
   ‚Ä¢ Publishing: 95%+ posts succeed
   ‚Ä¢ Analytics: Data accurate within 5%

4. Learning Tests
   ‚Ä¢ After 50 videos, identify 3 patterns
   ‚Ä¢ Test 1 recommendation via A/B test
   ‚Ä¢ Verify winning recommendation improves metrics
   ‚Ä¢ Check auto-adjustment applies correctly

5. Monitoring Tests
   ‚Ä¢ All logs captured
   ‚Ä¢ Errors trigger notifications
   ‚Ä¢ Daily summary email arrives
   ‚Ä¢ Notion updates post correctly
   ‚Ä¢ Dashboard shows real-time data

‚úÖ Acceptance Criteria:
‚Ä¢ System runs for 7 consecutive days
‚Ä¢ Generates 4+ videos per day (28 total)
‚Ä¢ 90%+ videos pass initial QC
‚Ä¢ 80%+ videos approved
‚Ä¢ 95%+ posts succeed
‚Ä¢ Zero critical failures
‚Ä¢ All errors handled gracefully
‚Ä¢ Learning loop shows improvement
‚Ä¢ Total human time < 30 min/day (just approvals)

üìä Estimated Effort: 8 hours setup + 7 days monitoring

üß™ Success Metrics:
‚Ä¢ Uptime: 99.9%
‚Ä¢ Video quality: 9/10 average
‚Ä¢ Publishing success: 95%+
‚Ä¢ Cost: < $100 for the week
‚Ä¢ Engagement: Baseline established
‚Ä¢ Improvements: 10%+ by end of week

üìù Deliverables:
‚Ä¢ Test report with all metrics
‚Ä¢ Error log with resolutions
‚Ä¢ Performance benchmarks
‚Ä¢ Recommendation for production
‚Ä¢ Launch checklist""",
    milestone="M5: Publishing",
    status="Todo",
    owner="Claude + Codex + Gurvinder",
    priority="High",
    eod_date=m5_start + timedelta(days=7),
    effort_hours=8,
    tags=["testing", "integration", "launch", "automation"],
    acceptance_criteria="Runs 7 days, 28 videos, 90% QC pass, 80% approval, 95% publish, zero critical failures, <30 min/day human time"
)

print("\n"+"="*80)
print("‚úÖ M4 & M5 COMPLETE WITH FULL DETAILS!")
print("="*80)
print("\nüìä Summary:")
print("  ‚Ä¢ M4: 3 detailed tasks (40 hours total)")
print("  ‚Ä¢ M5: 4 detailed tasks (48 hours total)")
print("  ‚Ä¢ All tasks include:")
print("    - Comprehensive task breakdown")
print("    - Technical implementation details")
print("    - File structures")
print("    - Acceptance criteria")
print("    - Testing procedures")
print("    - Effort estimates")
print("    - Tags for filtering")
print("\nüéØ Total structure now 100% complete!")
print("="*80)
